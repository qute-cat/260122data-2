import streamlit as st
import pandas as pd
import altair as alt
import re

# -----------------------------
# í˜ì´ì§€ ì„¤ì •
# -----------------------------
st.set_page_config(
    page_title="AI Agent Evolution",
    layout="wide"
)

# -----------------------------
# session_state ì´ˆê¸°í™” (ğŸ”¥ í•µì‹¬)
# -----------------------------
if "questions" not in st.session_state:
    st.session_state.questions = []

# -----------------------------
# í˜ì´ì§€ íƒ€ì´í‹€
# -----------------------------
st.title("ğŸ¤– AI AgentëŠ” ì–´ë–»ê²Œ ì§„í™”í•˜ê³  ìˆì„ê¹Œ?")
st.caption("AI Agent ìƒíƒœê³„ ë°ì´í„° ê¸°ë°˜ íŠ¸ë Œë“œ íƒìƒ‰")

# -----------------------------
# ë°ì´í„° ë¡œë“œ (ì¸ì½”ë”© ì•ˆì „ ì²˜ë¦¬)
# -----------------------------
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("AI_Agents_Ecosystem_2026.csv", encoding="utf-8")
    except UnicodeDecodeError:
        df = pd.read_csv("AI_Agents_Ecosystem_2026.csv", encoding="cp949")

    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
    df["Year"] = df["Date"].dt.year

    return df

df = load_data()

# =============================
# A. ì—°ë„ë³„ íŠ¸ë Œë“œ
# =============================
st.subheader("A. ì—°ë„ë³„ AI Agent íŠ¸ë Œë“œ ë³€í™”")

yearly_trend = (
    df.groupby("Year")
    .size()
    .reset_index(name="Count")
)

chart_a = (
    alt.Chart(yearly_trend)
    .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
    .encode(
        x=alt.X("Year:O", title="ì—°ë„"),
        y=alt.Y("Count:Q", title="ì‚¬ë¡€ ìˆ˜"),
        tooltip=["Year", "Count"]
    )
    .properties(height=380)
)

st.altair_chart(chart_a, use_container_width=True)

st.markdown("""
ğŸ‘‰ **A ë‹¨ê³„ ìš”ì•½**  
AI Agent ê´€ë ¨ ë…¼ì˜ëŠ” ìµœê·¼ìœ¼ë¡œ ì˜¬ìˆ˜ë¡ **í­ë°œì ìœ¼ë¡œ ì¦ê°€**í•˜ê³  ìˆìŠµë‹ˆë‹¤.
""")

st.divider()

# =============================
# B. ì—­í•  ì§„í™” ë‹¨ê³„ ë¶„ì„
# =============================
st.subheader("B. AI Agent ì—­í•  ì§„í™” ë‹¨ê³„")

st.markdown("""
AI AgentëŠ” ë‹¨ìˆœí•œ í”„ë¡œê·¸ë¨ì´ ì•„ë‹ˆë¼  
**ì–´ë–¤ ì—­í• ì„ ë§¡ê³  ìˆëŠ” ì¡´ì¬ì¸ê°€**ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# -----------------------------
# ì—­í•  ë‹¨ê³„ ë¶„ë¥˜ í•¨ìˆ˜
# -----------------------------
def classify_role(text):
    text = str(text).lower()

    if re.search(r"multi|ecosystem|collaboration|swarm", text):
        return "4ï¸âƒ£ Multi-Agent System"
    if re.search(r"autonomous|self|decision|agentic", text):
        return "3ï¸âƒ£ Autonomous Agent"
    if re.search(r"chat|assistant|conversation|dialog", text):
        return "2ï¸âƒ£ Conversational Agent"
    return "1ï¸âƒ£ Task / Rule Agent"

df["Role_Stage"] = df["Description"].apply(classify_role)

# -----------------------------
# ì—°ë„ Ã— ì—­í•  ë‹¨ê³„ ì§‘ê³„
# -----------------------------
role_trend = (
    df.groupby(["Year", "Role_Stage"])
    .size()
    .reset_index(name="Count")
)

chart_b = (
    alt.Chart(role_trend)
    .mark_bar()
    .encode(
        x=alt.X("Year:O", title="ì—°ë„"),
        y=alt.Y("Count:Q", title="ì‚¬ë¡€ ìˆ˜"),
        color=alt.Color(
            "Role_Stage:N",
            title="AI Agent ì—­í•  ë‹¨ê³„",
            scale=alt.Scale(
                domain=[
                    "1ï¸âƒ£ Task / Rule Agent",
                    "2ï¸âƒ£ Conversational Agent",
                    "3ï¸âƒ£ Autonomous Agent",
                    "4ï¸âƒ£ Multi-Agent System"
                ]
            )
        ),
        tooltip=["Year", "Role_Stage", "Count"]
    )
    .properties(height=420)
)

st.altair_chart(chart_b, use_container_width=True)

st.divider()

# =============================
# C. ì „ê³µÂ·ì§„ë¡œ ì—°ê²°
# =============================
st.subheader("C. AI ì‹œëŒ€, ì „ê³µÂ·ì§„ë¡œëŠ” ì–´ë–»ê²Œ ë‹¬ë¼ì§ˆê¹Œ?")

role_map = pd.DataFrame({
    "AI Agent ë‹¨ê³„": [
        "1ï¸âƒ£ Task / Rule Agent",
        "2ï¸âƒ£ Conversational Agent",
        "3ï¸âƒ£ Autonomous Agent",
        "4ï¸âƒ£ Multi-Agent System"
    ],
    "AIì˜ ì—­í• ": [
        "ì •í•´ì§„ ì‘ì—… ìˆ˜í–‰",
        "ëŒ€í™”Â·ì‘ë‹µÂ·ë„ì›€",
        "ìŠ¤ìŠ¤ë¡œ íŒë‹¨Â·í–‰ë™",
        "ì—¬ëŸ¬ AI ê°„ í˜‘ë ¥"
    ],
    "ì‚¬ëŒì—ê²Œ ì¤‘ìš”í•´ì§€ëŠ” ì—­ëŸ‰": [
        "ë¬¸ì œ ì •ì˜, ëª©í‘œ ì„¤ì •",
        "ê³µê°, ì„¤ëª…, ì†Œí†µ",
        "íŒë‹¨ ê¸°ì¤€ ì„¤ê³„, ìœ¤ë¦¬",
        "ê¸°íš, ì¡°ì •, ë¦¬ë”ì‹­"
    ],
    "ì—°ê²°ë˜ëŠ” ì „ê³µ ì˜ˆì‹œ": [
        "ì‚°ì—…ê³µí•™, ê¸°íš, í–‰ì •",
        "ì‹¬ë¦¬í•™, êµìœ¡, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜",
        "ë²•, ì² í•™, ë°ì´í„° í•´ì„",
        "ê²½ì˜, ì •ì±…, ìœµí•©ì „ê³µ"
    ]
})

st.dataframe(role_map, use_container_width=True)

st.divider()

# =============================
# D. í•™ìƒ ì§ˆë¬¸ ê¸°ë°˜ ì¶”ì²œ
# =============================
st.header("â‘¤ í•™ìƒ ì§ˆë¬¸ ê¸°ë°˜ ë§ì¶¤ ì „ê³µÂ·ì§„ë¡œ íŒíŠ¸")

# -----------------------------
# ê´€ì‹¬ ì˜ì—­ ì¶”ë¡  í•¨ìˆ˜ (ëˆ„ë½ ë³´ì™„)
# -----------------------------
def infer_interest(question):
    q = question.lower()

    if re.search(r"ì½”ë”©|ê°œë°œ|í”„ë¡œê·¸ë˜ë°|ai|ê¸°ìˆ ", q):
        return "ê¸°ìˆ Â·ê°œë°œ"
    if re.search(r"ì‚¬ëŒ|ì‹¬ë¦¬|ìƒë‹´|êµìœ¡", q):
        return "ì¸ê°„ì´í•´Â·ì‹¬ë¦¬"
    if re.search(r"ê¸°íš|ë¬¸ì œ|ì „ëµ", q):
        return "ê¸°íšÂ·ë¬¸ì œí•´ê²°"
    if re.search(r"ìœ¤ë¦¬|ë²•|ì‚¬íšŒ|ì •ì±…", q):
        return "íŒë‹¨Â·ìœ¤ë¦¬Â·ì‚¬íšŒ"
    if re.search(r"ë¶ˆì•ˆ|ëª¨ë¥´ê² |ê±±ì •", q):
        return "ë¶ˆì•ˆÂ·ìê¸°íš¨ëŠ¥"
    return "ë³µí•©/íƒìƒ‰ì¤‘"

interest_role_map = {
    "ê¸°ìˆ Â·ê°œë°œ": {
        "AI ì‹œëŒ€ ì—­í• ": "AIë¥¼ êµ¬í˜„Â·ê°œì„ í•˜ëŠ” ì‚¬ëŒ",
        "ì¶”ì²œ ì „ê³µ": "ì»´í“¨í„°ê³µí•™, ì¸ê³µì§€ëŠ¥, ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤"
    },
    "ì¸ê°„ì´í•´Â·ì‹¬ë¦¬": {
        "AI ì‹œëŒ€ ì—­í• ": "AIì™€ ì‚¬ëŒì„ ì—°ê²°í•˜ëŠ” ì‚¬ëŒ",
        "ì¶”ì²œ ì „ê³µ": "ì‹¬ë¦¬í•™, êµìœ¡í•™, ìƒë‹´, UX"
    },
    "ê¸°íšÂ·ë¬¸ì œí•´ê²°": {
        "AI ì‹œëŒ€ ì—­í• ": "AIê°€ í’€ ë¬¸ì œë¥¼ ì •ì˜í•˜ëŠ” ì‚¬ëŒ",
        "ì¶”ì²œ ì „ê³µ": "ì‚°ì—…ê³µí•™, ê²½ì˜, ê¸°íš, í–‰ì •"
    },
    "íŒë‹¨Â·ìœ¤ë¦¬Â·ì‚¬íšŒ": {
        "AI ì‹œëŒ€ ì—­í• ": "AIì˜ íŒë‹¨ ê¸°ì¤€ì„ ì„¤ê³„í•˜ëŠ” ì‚¬ëŒ",
        "ì¶”ì²œ ì „ê³µ": "ë²•, ì² í•™, ì‚¬íšŒê³¼í•™, ì •ì±…"
    },
    "ë¶ˆì•ˆÂ·ìê¸°íš¨ëŠ¥": {
        "AI ì‹œëŒ€ ì—­í• ": "ìê¸° íƒìƒ‰ì´ í•„ìš”í•œ ë‹¨ê³„",
        "ì¶”ì²œ ì „ê³µ": "ìœµí•©ì „ê³µ, ììœ ì „ê³µ"
    },
    "ë³µí•©/íƒìƒ‰ì¤‘": {
        "AI ì‹œëŒ€ ì—­í• ": "ì—¬ëŸ¬ ì—­í• ì„ íƒìƒ‰ ì¤‘ì¸ ì‚¬ëŒ",
        "ì¶”ì²œ ì „ê³µ": "ìœµí•©ì „ê³µ, ë³µìˆ˜ì „ê³µ, ì—°ê³„ì „ê³µ"
    }
}

if st.session_state.questions:
    rec_data = []

    for q in st.session_state.questions:
        interest = infer_interest(q)
        role_info = interest_role_map[interest]

        rec_data.append({
            "í•™ìƒ ì§ˆë¬¸": q,
            "ê´€ì‹¬ ì˜ì—­": interest,
            "AI ì‹œëŒ€ ì—­í• ": role_info["AI ì‹œëŒ€ ì—­í• "],
            "ì¶”ì²œ ì „ê³µ ë°©í–¥": role_info["ì¶”ì²œ ì „ê³µ"]
        })

    rec_df = pd.DataFrame(rec_data)
    st.dataframe(rec_df, use_container_width=True)

else:
    st.info("ì•„ì§ ì§ˆë¬¸ì´ ì—†ì–´ ë§ì¶¤ ì¶”ì²œì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
