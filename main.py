import streamlit as st
import pandas as pd
from urllib.parse import urlparse
import plotly.express as px

# =========================
# 1. ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(
    page_title="AI Agents Ecosystem Analysis",
    layout="wide"
)

st.title("ğŸ“Š AI ì—ì´ì „íŠ¸ ì¼ìë¦¬ ìƒíƒœê³„ ì—°ë„Â·êµ­ê°€ ë¶„ì„")
st.markdown(
    """
    ì´ ì›¹ì•±ì€ **AI ì—ì´ì „íŠ¸ ê´€ë ¨ ì¼ìë¦¬Â·í”„ë¡œì íŠ¸Â·ê¸°ìˆ  ê¸°íšŒ ë°ì´í„°**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ  
    **ì—°ë„ë³„ ë³€í™”**ì™€ **ë„ë©”ì¸ ê¸°ë°˜ êµ­ê°€ ìƒíƒœê³„ ë¶„í¬**ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    """
)

# =========================
# 2. ë°ì´í„° ë¡œë”©
# =========================
@st.cache_data
def load_csv(file):
    return pd.read_csv(file, encoding="cp949")

# ê¸°ë³¸ ë°ì´í„°
BASE_FILE = "AI_Agents_Ecosystem_2026.csv"
df_list = []

try:
    base_df = load_csv(BASE_FILE)
    df_list.append(base_df)
except:
    st.error("ê¸°ë³¸ ë°ì´í„° íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ì¶”ê°€ ë°ì´í„° ì—…ë¡œë“œ
uploaded_files = st.file_uploader(
    "ğŸ“‚ ë™ì¼í•œ í˜•ì‹ì˜ CSV íŒŒì¼ ì¶”ê°€ ì—…ë¡œë“œ (ì„ íƒ)",
    type="csv",
    accept_multiple_files=True
)

if uploaded_files:
    for file in uploaded_files:
        df_list.append(load_csv(file))

df = pd.concat(df_list, ignore_index=True)

# =========================
# 3. ë„ë©”ì¸ â†’ êµ­ê°€ ë¶„ë¥˜
# =========================
TLD_COUNTRY_MAP = {
    "kr": "South Korea",
    "jp": "Japan",
    "cn": "China",
    "tw": "Taiwan",
    "sg": "Singapore",
    "hk": "Hong Kong",
    "de": "Germany",
    "fr": "France",
    "uk": "United Kingdom",
    "gb": "United Kingdom",
    "nl": "Netherlands",
    "ca": "Canada",
    "au": "Australia",
    "in": "India",
    "br": "Brazil"
}

def extract_domain(url):
    if pd.isna(url):
        return None
    try:
        return urlparse(url).netloc.replace("www.", "").lower()
    except:
        return None

def infer_country(domain):
    if domain is None:
        return "Unknown"
    tld = domain.split(".")[-1]
    if tld in TLD_COUNTRY_MAP:
        return TLD_COUNTRY_MAP[tld]
    if tld in ["com", "io", "ai", "org", "net"]:
        return "Global"
    return "Other"

df["domain"] = df["Link"].apply(extract_domain)
df["country"] = df["domain"].apply(infer_country)

# =========================
# 4. ì—°ë„ ì¶”ì¶œ
# =========================
df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
df["Year"] = df["Date"].dt.year

# =========================
# 5. ì—°ë„ë³„ Ã— êµ­ê°€ë³„ ì§‘ê³„
# =========================
year_country = (
    df.groupby(["Year", "country"])
      .size()
      .reset_index(name="count")
)

# =========================
# 6. ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”
# =========================
st.subheader("ğŸ“ˆ ì—°ë„ë³„ AI ì—ì´ì „íŠ¸ ìƒíƒœê³„ êµ­ê°€ ë¶„í¬")

fig = px.line(
    year_country,
    x="Year",
    y="count",
    color="country",
    markers=True,
    title="Yearly Distribution of AI Agent Ecosystem by Country (Domain-based)"
)

fig.update_layout(
    xaxis_title="Year",
    yaxis_title="Number of Opportunities",
    legend_title="Country (Inferred from Domain)"
)

st.plotly_chart(fig, use_container_width=True)

# =========================
# 7. í•´ì„ ìë™ ìƒì„±
# =========================
st.subheader("ğŸ§  ë¶„ì„ í•´ì„")

latest_year = year_country["Year"].max()
latest_data = year_country[year_country["Year"] == latest_year]

global_ratio = (
    latest_data.loc[latest_data["country"] == "Global", "count"].sum()
    / latest_data["]()_
